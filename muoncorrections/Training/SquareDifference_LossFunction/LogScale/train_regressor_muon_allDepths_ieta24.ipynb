{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "0a248537-a46f-4db0-b91f-c9fcb1827f63"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "159ee908-ee70-4719-bf31-e67da99e8c61"
    }
   },
   "outputs": [],
   "source": [
    "# load saved df\n",
    "df = pd.read_pickle('test.pkl')\n",
    "print (df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e42911ea-1e5e-4460-830f-e3c48218d94b"
    }
   },
   "outputs": [],
   "source": [
    "# filter events\n",
    "ieta=24\n",
    "df = df.loc[abs(df[b'hcal_ieta']) == ieta]\n",
    "\n",
    "df = df.loc[df[\"b'hcal_edepth1'_x\"] > 0.00001]\n",
    "df = df.loc[df[\"b'hcal_edepth1'_y\"] > 0.00001]\n",
    "\n",
    "df = df.loc[df[\"b'hcal_edepth2'_x\"] > 0.00001]\n",
    "df = df.loc[df[\"b'hcal_edepth2'_y\"] > 0.00001]\n",
    "\n",
    "df = df.loc[df[\"b'hcal_edepth3'_x\"] > 0.00001]\n",
    "df = df.loc[df[\"b'hcal_edepth3'_y\"] > 0.00001]\n",
    "\n",
    "df = df.loc[df[\"b'hcal_edepth4'_x\"] > 0.00001]\n",
    "df = df.loc[df[\"b'hcal_edepth4'_y\"] > 0.00001]\n",
    "\n",
    "df = df.loc[df[\"b'hcal_edepth5'_x\"] > 0.00001]\n",
    "df = df.loc[df[\"b'hcal_edepth5'_y\"] > 0.00001]\n",
    "\n",
    "df = df.loc[df[\"b'hcal_edepth6'_x\"] > 0.00001]\n",
    "df = df.loc[df[\"b'hcal_edepth6'_y\"] > 0.00001]\n",
    "\n",
    "if ieta in range (26,28):\n",
    "    df = df.loc[df[\"b'hcal_edepth7'_x\"] > 0.00001]\n",
    "    df = df.loc[df[\"b'hcal_edepth7'_y\"] > 0.00001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"b'hcal_edepth1'_x\"]=np.log(10000*df[\"b'hcal_edepth1'_x\"])\n",
    "df[\"b'hcal_edepth1'_y\"]=np.log(10000*df[\"b'hcal_edepth1'_y\"])\n",
    "\n",
    "df[\"b'hcal_edepth2'_x\"]=np.log(10000*df[\"b'hcal_edepth2'_x\"])\n",
    "df[\"b'hcal_edepth2'_y\"]=np.log(10000*df[\"b'hcal_edepth2'_y\"])\n",
    "\n",
    "df[\"b'hcal_edepth3'_x\"]=np.log(10000*df[\"b'hcal_edepth3'_x\"])\n",
    "df[\"b'hcal_edepth3'_y\"]=np.log(10000*df[\"b'hcal_edepth3'_y\"])\n",
    "\n",
    "df[\"b'hcal_edepth4'_x\"]=np.log(10000*df[\"b'hcal_edepth4'_x\"])\n",
    "df[\"b'hcal_edepth4'_y\"]=np.log(10000*df[\"b'hcal_edepth4'_y\"])\n",
    "\n",
    "df[\"b'hcal_edepth5'_x\"]=np.log(10000*df[\"b'hcal_edepth5'_x\"])\n",
    "df[\"b'hcal_edepth5'_y\"]=np.log(10000*df[\"b'hcal_edepth5'_y\"])\n",
    "\n",
    "df[\"b'hcal_edepth6'_x\"]=np.log(10000*df[\"b'hcal_edepth6'_x\"])\n",
    "df[\"b'hcal_edepth6'_y\"]=np.log(10000*df[\"b'hcal_edepth6'_y\"])\n",
    "\n",
    "if ieta in range (26,28):\n",
    "    df[\"b'hcal_edepth7'_x\"]=np.log(10000*df[\"b'hcal_edepth7'_x\"])\n",
    "    df[\"b'hcal_edepth7'_y\"]=np.log(10000*df[\"b'hcal_edepth7'_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep originals before scaling\n",
    "df['hcal_edepth1_un'] = df[\"b'hcal_edepth1'_x\"]\n",
    "df['hcal_edepth2_un'] = df[\"b'hcal_edepth2'_x\"]\n",
    "df['hcal_edepth3_un'] = df[\"b'hcal_edepth3'_x\"]\n",
    "df['hcal_edepth4_un'] = df[\"b'hcal_edepth4'_x\"]\n",
    "df['hcal_edepth5_un'] = df[\"b'hcal_edepth5'_x\"]\n",
    "df['hcal_edepth6_un'] = df[\"b'hcal_edepth6'_x\"]\n",
    "df['hcal_edepth7_un'] = df[\"b'hcal_edepth7'_x\"]\n",
    "\n",
    "df['hcal_ieta_un'] = df[b'hcal_ieta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling input vars\n",
    "cols_to_minmax =[b'pt_of_muon',b'eta_of_muon',b'phi_of_muon',b'energy_of_muon',b'hcal_ieta',\n",
    "                b'hcal_iphi',     b'IsolationR04',     b'IsolationR03',\n",
    "                b'ecal_3into3',      b'hcal_3into3', \n",
    "                b'ecal_3x3',         b'hcal_1x1',\n",
    "               \"b'hcal_edepth1'_x\", \"b'hcal_edepth2'_x\", \"b'hcal_edepth3'_x\",\n",
    "               \"b'hcal_edepth4'_x\", \"b'hcal_edepth5'_x\", \"b'hcal_edepth6'_x\",\n",
    "               \"b'hcal_edepth7'_x\"]\n",
    "\n",
    "\n",
    "df[cols_to_minmax] = df[cols_to_minmax].apply(lambda x: (x - x.min()) /  (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ieta)\n",
    "for i in (df.keys()):\n",
    "    print (i)\n",
    "    if ieta in range (22,26):\n",
    "        if i == \"b'hcal_edepth7'_x\":\n",
    "            continue\n",
    "        if i == \"b'hcal_edepth7'_y\":\n",
    "            continue\n",
    "        if i == \"b'hcal_edepth7'_un\":\n",
    "            continue\n",
    "    plt.hist(df[i],bins=100,label=str(i),alpha=0.4)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b4717cf1-c9f3-4ecd-a505-1eddfe074421"
    }
   },
   "outputs": [],
   "source": [
    "data = df.values\n",
    "print (data)\n",
    "ntest = 20000\n",
    "testindx = data.shape[0] - ntest\n",
    "\n",
    "X_train_depth1 = data[:testindx,np.r_[0:12,12]]\n",
    "X_train_depth2 = data[:testindx,np.r_[0:12,13]]\n",
    "X_train_depth3 = data[:testindx,np.r_[0:12,14]]\n",
    "X_train_depth4 = data[:testindx,np.r_[0:12,15]]\n",
    "X_train_depth5 = data[:testindx,np.r_[0:12,16]]\n",
    "X_train_depth6 = data[:testindx,np.r_[0:12,17]]\n",
    "X_train_depth7 = data[:testindx,np.r_[0:12,18]]\n",
    "\n",
    "Y_train = data[:testindx,20]               \n",
    "X_test = data[testindx:,:]\n",
    "print (X_test.shape) \n",
    "#print (\"shape of X_train:\",X_train.shape)\n",
    "print (\"shape of Y_train:\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b867ec5d-fc25-4536-a353-4a87f1391ccb"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample weights\n",
    "histoAR = Y_train.copy()\n",
    "nbins = 4 ### works best[4 with no sqrt / 500 with sqrt normed] / 1000 with norm*100 / 4000 ok no sqrt\n",
    "true_hist = np.histogram(histoAR,bins = nbins,range=(np.min(Y_train)-0.001,np.max(Y_train)+0.001))\n",
    "binweight = true_hist[0][np.digitize(histoAR,true_hist[1]) - 1]\n",
    "print (\"true_hist[0] = \", true_hist[0])\n",
    "binweight = 1/binweight\n",
    "binweight = 100*binweight/np.sum(np.unique(binweight)) ## 5000/5 ok\n",
    "print(\"sum weight:\",np.sum(np.unique(binweight)))\n",
    "print(\"true_hist\",true_hist[0])\n",
    "print(\"binweight\",binweight)\n",
    "print(\"weight_vals:\",np.unique(binweight))\n",
    "plt.hist(histoAR,bins=nbins)\n",
    "for i in true_hist[1]:\n",
    "    plt.axvline(i,color='r')\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_PU_depth1=df['hcal_edepth1_un']\n",
    "true_PU_depth2=df['hcal_edepth2_un']\n",
    "true_PU_depth3=df['hcal_edepth3_un']\n",
    "true_PU_depth4=df['hcal_edepth4_un']\n",
    "true_PU_depth5=df['hcal_edepth5_un']\n",
    "true_PU_depth6=df['hcal_edepth6_un']\n",
    "true_PU_depth7=df['hcal_edepth7_un']\n",
    "\n",
    "depth1 = 'Depth: 1'\n",
    "depth2 = 'Depth: 2'\n",
    "depth3 = 'Depth: 3'\n",
    "depth4 = 'Depth: 4'\n",
    "depth5 = 'Depth: 5'\n",
    "depth6 = 'Depth: 6'\n",
    "depth7 = 'Depth: 7'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as kb\n",
    "def custom_loss_depth1(preds_depth1,targets):\n",
    "    return (kb.square(preds_depth1-targets))\n",
    "\n",
    "def custom_loss_depth2(preds_depth2,targets):\n",
    "    return (kb.square(preds_depth2-targets))\n",
    "\n",
    "def custom_loss_depth3(preds_depth3,targets):\n",
    "    return (kb.square(preds_depth3-targets))\n",
    "\n",
    "def custom_loss_depth4(preds_depth4,targets):\n",
    "    return (kb.square(preds_depth4-targets))\n",
    "\n",
    "def custom_loss_depth5(preds_depth5,targets):\n",
    "    return (kb.square(preds_depth5-targets))\n",
    "\n",
    "def custom_loss_depth6(preds_depth6,targets):\n",
    "    return (kb.square(preds_depth6-targets))\n",
    "\n",
    "def custom_loss_depth7(preds_depth7,targets):\n",
    "    return (kb.square(preds_depth7-targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_model(X_train):\n",
    "    PYTHONHASHSEED=0\n",
    "    from numpy.random import seed\n",
    "    seed(1)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(2)\n",
    "\n",
    "    from keras.layers import LeakyReLU\n",
    "    from keras import optimizers\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, input_shape=(X_train.shape[1],)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(600))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(600))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(20))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_loss(history_depth):\n",
    "    print(history_depth.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history_depth.history['loss'])\n",
    "    plt.plot(history_depth.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt1 = plt.show()\n",
    "    return plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(true_PU, preds, targets, title_depth):\n",
    "    from matplotlib import gridspec\n",
    "    %matplotlib inline\n",
    "    i=0\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    gs = gridspec.GridSpec(2,1, height_ratios=[2, 1]) \n",
    "    ax = plt.subplot(gs[0])\n",
    "    \n",
    "    a=round(np.mean(targets[:,i]),3)\n",
    "    ax.hist(targets[:,i], range=(0,20), bins=100, color = 'red', label='truth no PU, Mean='+str(a),histtype='step',linewidth=1.5)\n",
    "    \n",
    "    b=round(np.mean(preds[:,i]),3)\n",
    "    ax.hist(preds[:,i], range=(0,20), bins=100, color = 'green', label='predicted, Mean='+str(b),histtype='step',linewidth=1.5)\n",
    "    \n",
    "    plt.hist(true_PU, range=(0,20), bins=100, color = 'yellow', label='truth PU',histtype='step',linewidth=1.5)\n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_yscale('log')    \n",
    "    \n",
    "    plt.title('ieta: '+str(ieta), loc='left')\n",
    "    plt.title(str(title_depth), loc='right')\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "    \n",
    "    rat = (preds[:,i]/targets[:,i])\n",
    "    ax1.plot(rat, 'o')\n",
    "    ax1.axis([0, 20, -1, 2])\n",
    "    plt.ylabel('predicted / truth no PU')\n",
    "    ax1.plot([0, 20], [1, 1])\n",
    "    plt.savefig('Plots/Final/ieta'+str(ieta)+'_'+str(title_depth)+'.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return plt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model_name,title_depth):\n",
    "    import os\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    model_name.save('models/model_ieta'+str(ieta)+'_'+str(title_depth)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=My_model(X_train_depth1)\n",
    "model2=My_model(X_train_depth2)\n",
    "model3=My_model(X_train_depth3)\n",
    "model4=My_model(X_train_depth4)\n",
    "model5=My_model(X_train_depth5)\n",
    "model6=My_model(X_train_depth6)\n",
    "model7=My_model(X_train_depth7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=custom_loss_depth1,optimizer='adam')\n",
    "model1.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history1 = model1.fit(X_train_depth1,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n",
    "\n",
    "\n",
    "model2.compile(loss=custom_loss_depth2,optimizer='adam')\n",
    "model2.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history2 = model2.fit(X_train_depth2,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n",
    "\n",
    "\n",
    "model3.compile(loss=custom_loss_depth3,optimizer='adam')\n",
    "model3.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history3 = model3.fit(X_train_depth3,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n",
    "\n",
    "\n",
    "model4.compile(loss=custom_loss_depth4,optimizer='adam')\n",
    "model4.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history4 = model4.fit(X_train_depth4,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n",
    "\n",
    "model5.compile(loss=custom_loss_depth5,optimizer='adam')\n",
    "model5.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history5 = model5.fit(X_train_depth5,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n",
    "\n",
    "\n",
    "model6.compile(loss=custom_loss_depth6,optimizer='adam')\n",
    "model6.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history6 = model6.fit(X_train_depth6,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n",
    "\n",
    "model7.compile(loss=custom_loss_depth7,optimizer='adam')\n",
    "model7.summary()\n",
    "print (\"fitting now=========>\")\n",
    "history7 = model7.fit(X_train_depth7,Y_train , batch_size=5000, epochs=500, validation_split=0.2,\n",
    "                      verbose=1,sample_weight=binweight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_loss(history1)\n",
    "model_loss(history2)\n",
    "model_loss(history3)\n",
    "model_loss(history4)\n",
    "model_loss(history5)\n",
    "model_loss(history6)\n",
    "if ieta in range (26,28):\n",
    "    model_loss(history7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "preds1 = model1.predict(X_test[:,np.r_[0:12,12]])\n",
    "preds2 = model2.predict(X_test[:,np.r_[0:12,13]])\n",
    "preds3 = model3.predict(X_test[:,np.r_[0:12,14]])\n",
    "preds4 = model4.predict(X_test[:,np.r_[0:12,15]])\n",
    "preds5 = model5.predict(X_test[:,np.r_[0:12,16]])\n",
    "preds6 = model6.predict(X_test[:,np.r_[0:12,17]])\n",
    "preds7 = model7.predict(X_test[:,np.r_[0:12,18]])\n",
    "\n",
    "targets = X_test[:,20]\n",
    "uncorrected = X_test[:,27]\n",
    "targets = targets.reshape(targets.shape[0],1)\n",
    "uncorrected = uncorrected.reshape(uncorrected.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution(true_PU_depth1, preds1, targets, depth1)\n",
    "distribution(true_PU_depth2, preds2, targets, depth2)\n",
    "distribution(true_PU_depth3, preds3, targets, depth3)\n",
    "distribution(true_PU_depth4, preds4, targets, depth4)\n",
    "distribution(true_PU_depth5, preds5, targets, depth5)\n",
    "distribution(true_PU_depth6, preds6, targets, depth6)\n",
    "if ieta in range (26,28):\n",
    "    distribution(true_PU_depth7, preds7, targets, depth7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save(model1, depth1)\n",
    "model_save(model2, depth2)\n",
    "model_save(model3, depth3)\n",
    "model_save(model4, depth4)\n",
    "model_save(model5, depth5)\n",
    "model_save(model6, depth6)\n",
    "if ieta in range (26,28):\n",
    "    model_save(model7, depth7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-data-project",
   "language": "python",
   "name": "py3-data-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
